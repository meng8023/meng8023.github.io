---
title: Nginx使用帮助文档
tags: jekyll
key: 20190310
---

**Nginx使用帮助文档**
---------------

nginx -s stop

fast shutdown快速关机

nginx -s quit

graceful shutdown优雅的关机

nginx -s reload

changing configuration, starting new worker processes with a new configuration, graceful shutdown of old worker processes

更改配置, 使用新配置启动新的工作进程, 正常关闭旧的工作进程

nginx -s reopen

re-opening log files

重新打开日志文件

Tpc 负载均衡添加配置部分

stream {

    server {

        listen 3037;

proxy\_pass wcf\_tcp;

proxy\_buffer\_size 16k;

    }

upstream wcf_tcp{

server 127.0.0.1:8044 weight=1 max\_fails=1 fail\_timeout=10s ;

server 192.168.1.200:8044 weight=1 max\_fails=1 fail\_timeout=10s ;

zone backends 64k;

}

}

目录:

1:什么是nginx

2:搭建环境、配置

3:前提条件：缓存共享session

===========================================

1.0背景

对于一个大型网站来说，负载均衡是永恒的话题。随着硬件技术的迅猛发展，越来越多的负载均衡硬件设备涌现出来，如F5 BIG-IP、Citrix NetScaler、Radware等等，虽然可以解决问题，但其高昂的价格却往往令人望而却步，因此负载均衡软件仍然是大部分公司的不二之选。nginx作为webserver的后起之秀，其优秀的反向代理功能和灵活的负载均衡策略受到了业界广泛的关注。

官网： http://nginx.org/en/docs/windows.html

淘宝Tengine:   http://tengine.taobao.org/

1.1介绍

Nginx （发音同 engine x）是一款轻量级的Web 服务器／反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。  其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页伺服器中表现较好.目前中国大陆使用nginx网站用户有：新浪、网易、 腾讯、12306、迅雷等。

F5 BIG-IP、Citrix NetScaler、Radware等硬件加速器是操作于IOS网络模型的传输层，Nginx、apache是基于http反向代理方式，位于ISO模型的第七层应用层。直白些就是TCP UDP 和http协议的区别，Nginx不能为基于TCP协议的应用提供负载均衡。通过对HTTP报头的检查，可以检测出HTTP400、500和600系列的错误信息，因而能透明地将连接请求重新定向到另一台服务器，避免应用层故障。

1.2工作原理

nginx配置负载均衡工作在TCP/IP协议的第七层，即应用层，属于七层负载均衡。

Nginx使用反向代理达到负载均衡

http://blog.csdn.net/m13666368773/article/details/8060481

1.3示列

1.4架构图

1.5负载均衡策略

 nginx的负载均衡策略可以划分为两大类：内置策略和扩展策略。

    内置策略包含加权轮询和ip hash，在默认情况下这两种策略会编译进nginx内核，只需在nginx配置中指明参数即可。       

    扩展策略有很多，如fair、通用hash、consistent hash等，默认不编译进nginx内核。

1.5.1内置轮循策略

轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。Weight 指定轮询权值，Weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。

1.5.2、内置： ip_hash 策略

ip_hash：每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。但目前大部份应用的客户端都是共享上网方式，所以此策略在实际运用过程中，往往达不到效果。

1.5.3、扩展策略

fair：这是比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。**Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块**。

url_hash：此方法按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。**Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包**。

1.6、策略性能对比

![]({{ "/assets/images/Nginx2246.png" | absolute_url }})

1.7、负载均衡能给系统带来什么提高系统吞吐量

通过负载均衡，部署多个tomcat服务，提高系统的吞吐量降低单点故障

有效降低单点故障率，故障率随着后端服务的部署增多而下降，同时通过对HTTP报头的检查，自定义400\\500等错误显示页面，提供更友好服务降低对外网端口的依赖

负载均衡下只需要一个外网端口，但可以负载到内网多个tomcat上降低网络带宽

通过nginx的动静资源分离root、缓存加速proxy\_cache\_path、压缩GZIP、客户端缓

存expires等功能，减少数据传输量，降低带宽要求不停机升级系统

很多情况下，我们升级服务端系统文件后，需要重启服务以应用最新程序，通过Nginx负载实现不停服务完成重启

2、搭建nginx服务器

Nginx常用命令

Nginx在windows下是一个绿色软件

最稳定新版本是1.6.2

在cmd方式，进入nginx所在根目录

1、启动：nginx.exe或start nginx

2、停止：nginx -s stop或nginx -s quit

3、查看nginx版本： nginx –v或nginx -V

4、修改配置文件后重新载入： nginx -s reload

5、测试当前配置文件是否正确：nginx -t

参考：http://blog.csdn.net/aidenliu/article/details/6413342

http://www.cnblogs.com/mecity/archive/2011/06/17/2082786.html

2.1、 配置nginx服务器

配置文件nginx.conf

Nginx配置非常简单，只要在upstream里面多配置几个server就可以了

配置文件路径： .\\nginx\\conf\ nginx.conf

参考： http://passover.blog.51cto.com/2431658/648182

2.2、启动nginx服务器

启动后会在任务管理器中看到进程

启动nginx.exe或start nginx

用命令： tasklist /fi “imagename eq nginx.exe”可查看进程

这时说明已经启成功了，有两个进程。按照官方的解释，nginx是守护进程，其中一个是一直处理事件等待中，当有事件被触发时，就启动另外一个进程处理相关请求。如果在配置文件中配置了多个处理进程，那么显示为配置进程+1个进程

2.3、实际效果配置nginx.conf

启动nginx

查看nginx的启动状态

负载均衡的效果演示(加权轮询策略)、单点及多点故障场景、客户端缓存、压缩、动态(jsp\\php\\asp…)与静态(css\\js\\html\\jpg\\png\\bmp…)数据分离

403\\404错误自定义显示页面

停止nginx

3、前提条件：缓存共享session

什么是session

    Session是存储在服务器端的一个标识，记录着客户端访问者的多种信息，就像客户端的Cookie每个访问者都有自己独立的session，不能相互访问，即A用户不能访问B用户产生的session

3.1、为什么要缓存共享session

在多个tomcat负载均衡场景下

    我们的WEB应用程序，必须用到session对一些关键数据进行存储利用，而session又只能存储在服务端tomcat中，那么在负载均衡场景下，用户有可能第一次访问A服务，第二次有可能访问B服务，如果两台服务器的session没有共享，就无法实现协同工作，关键数据无法获取。

3.2、共享session的方案

1\. 使用tomcat自带的cluster方式，多个tomcat自动实时复制session信息，同一用户的session会被复制到多个tomcat服务器上，所以复制方式的效率比较低，在大并发下表现并不好。

  2\. 利用nginx的基于访问ip的hash路由策略，保证访问的ip始终被路由到同一个tomcat上，这个配置更简单。但是我们的应用很可能是某一个局域网大量用户同时登录，这样负载均衡就没什么作用了。

  3\. 利用memcached、redis把多个tomcat的session集中管理，这是最直接常用的解决方案，需要通过编码来实现。

  4、利用tomcat的扩展接口，引用memcached、redis的jar包，同时修改tomcat的web.xml配置文件，由tomcat将session交给外部系统管理，这种方案配置稍复杂，在WINDOWS下没有配置成功

\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-

作者：xiechunmei13

来源：CSDN

原文：https://blog.csdn.net/xiechunmei13/article/details/52910746

版权声明：本文为博主原创文章，转载请附上博文链接！